# Gemini Benchmark Report

- **Model used:** gemini-2.0-flash
- **Dataset:** data/mock-analysis.json
- **Run timestamp:** 2025-11-07T12:34:56.867Z

## Executive Summary

- TOON reduced input tokens by 400 (28.5%) compared with the other format.
- JSON responses arrived approximately 910.4ms faster than TOON.
- TOON conversion added 0.3ms of preprocessing time.

## Detailed Metrics

Format | Input tokens sent | Prompt tokens in response | Total tokens in response | Data prep time | Gemini response time
--- | --- | --- | --- | --- | ---
JSON | 1,404 | 1,398 | 1,590 | 0.0ms | 6691.6ms
TOON | 1,004 | 999 | 1,192 | 0.3ms | 7602.1ms

## Response Highlights

### JSON input
```json
{
  "summary": {
    "trends": [
      "Upsell Progress Bar in NA shows promise for premium conversion.",
      "Tiered Rewards in NA significantly improved retention.",
      "Gamified Onboarding in APAC boosted feature adoption.",…

### TOON input
> **TOON: Q3 2025 Marketing Performance**

*   **Key Trends:**
    *   NA: "Upsell Progress Bar" boosted premium conversions. "Tiered Rewards" improved retention.
    *   APAC: "Gamified Onboarding" increased feature adoption. APAC's churn is…

## Metric Definitions

- **Input tokens sent**: Tokens counted before calling Gemini (via the Count Tokens API).
- **Prompt tokens in response**: Tokens Gemini reports as used from the request after processing.
- **Total tokens in response**: Combined prompt and output token count reported by Gemini.
- **Data prep time**: Time spent preparing the payload (JSON formatting or TOON encoding).
- **Gemini response time**: End-to-end latency for `models.generateContent`.
- **Response highlights**: A short excerpt of Gemini's answer to compare tone and content.

